#############################################
# R namelist for testing HPC4Stats.skeleton #
#############################################


## Set project name key variables ##
####################################

## Project name  
  projectName<- "TEST"
  
## Number of workers
  nWorkers <- 2
  
## If not specified will be read from a UNIX environment variable
## Before the batch call to R in the bash UNIX shell: 
#   export HPC4StatsnWorkers=2
## NOTE: The batchSupervisor script will use the values from the
## environment for nWorkers, nTask1 and nTask2 even if these are given in the
## R namelist.
 
## The range of task IDs should be integers and make sense when you 
## execute the function call doTask(taskID).

  nTask1 <-  1 # starting task ID
  nTask2 <-  75 # ending task ID
  
## If not specified these will be read from a UNIX enviornment variable
## Before the batch call in the bash UNIX shell: 
#   export HPC4StatsnTask1=1
#   export HPC4StatsnTask2=10

## NOTE: Any of these variables existing in the environment will replace the ones
## in the .rnl script. I.e. environment assignments take precedence.

  
## Define some project specific data directories ##
###################################################

  projectDir<-".."
  dataDir  <- paste0(projectDir, "/data")
  
## The following data file name is only needed if you want to run the
## example in the HPC4Stats.skeleton. 
  dataFileName <- paste0(dataDir,"/","ozone2.rda")
  
## Remaining names can be changed but these below are suggested. 
  sourceDir<- paste( projectDir, "src",    sep="/")
  outputDir<- paste( projectDir, "output", sep="/")
  uniqueTime<- format(Sys.time(), format = "%Y%H%M%S")
  
## Optional: Can set chunkSize to control how many tasks will be executed
## before an output file is written. This is just to recover some output in
## case a large job crashes before completion or to gracefully divide the output into
## separate files. 
## If this is not set then no chunking is done   
#  chunkSize<- 15


## source any functions that are needed ##
###########################################

## The only required function is the doTask function that 
## each worker will be given to complete a task.
## It will be called by Rmpi as doTask(taskID) where taskID 
## is just an integer in the range of nTask1 to nTask2.
## Other  helper functions are optional.
## Here the test doTaskTEST is read in and reassigned as doTask. 
## This to get around the problem of multiple functions in your project being 
## named doTask and things getting confused.

  source( paste0(sourceDir,"/","doTaskTest.R") )
  

## define any objects in the supervisor session that will be needed ##
######################################################################

## taskTable in this case is the day to work on.
## i.e. task 1 will work on day 4. 
## in general the taskTable can be very complex and have all kinds of
## information connected with a given task ID
## Here we show how taskID "1" is mapped to be working on day "4" and so forth.
## There are 89 days in the ozone2 data set.
  taskTable<- (1:75) + 3
  
## reassign doTask to the specific one read in.
  doTask<- doTaskTest
  
## load the data file into supervisor session  
  load(dataFileName)


## data object names to broadcast to workers ##
###############################################

## They should be created or read into the supervisor session.
## Usually these are the functions and data objects setup above.
## If something is excluded from this list, the worker will not have it,
## but also note that being in the worker session makes them 
## available to the doTask function in the usual way that search paths work.

## Here namesDataObjects is not created so _all_ the objects in the 
## supervisor workspace will be broadcast to the workers.
## The code below would do this explicitly and is a more deliberate way
## to keep track of exactly what each worker needs.

#  namesDataObjects<- 
#  c(        
#     "ozone2",
#     "doTask",
#     "taskTable",
#     "dataFileName",
#     "projectDir",
#     "outputDir",
#     "sourceDir",
#     "dataDir"
#           )

##  names of libraries  ##
###########################

## Specifies libraries to load on each worker.
## These are also added on the supervisor.
## This is optional although given the nature of R
## in most cases you will need some extra 
## libraries. 
  namesLibraries<- c("fields")
  
## Also give the library location 
## Setting to NULL the default is to use system wide libraries.
## The option to change this is useful if one installs local libraries
## when using Cheyenne and it is handy to save them in the subdirectory lib
## of the project directory. 
   namesLibraryLocations<- NULL
#  namesLibraryLocations<- paste0( projectDir, "/lib")


## R code that will be run as a setup script by the supervisor ##
#################################################################

## This will be the last part of the code before broadcasting
## the objects to the workers, loading libraries, 
## and calling the Rmpi apply function.
## This part is optional and ideally the objects can be created in 
## a succint manner above in the object broadcast section.
## But keep in mind since this is just an R source file any R code
## can be inserted here to setup the computations. Often it is useful to do some
## error checking at this point.
