##################################################
# A more substantial application
# Fitting GPD to daily surface precip across
# 150X288 grid boxes (cheyenne)
# 50X288  grid boxes (laptop)
# returned are the GPD MLE parameters
##################################################


####################################################
# Running on a laptop/desktop or from the UNIX shell
#####################################################

# NOTE laptopGPDProduction.rnl
# is setup to read the original model output file that is in NETCDF format
# you will need to download this (large) file separately
# pr_day_CCSM4_historical_r1i1p1_19550101-19891231.nc
# and modify the line
# dataDir  <- "/Users/nychka/Dropbox/Data"
# to reflect where you have put the file 

#define and export name of R namelist This is always required.

    export HPC4StatsNAMELIST=laptopGPDProduction.rnl
    
# optional export number of workers and task range
# (These are optional if not set in the .rnl file
# or if you want to override the choice in the .rnl file).
#    export HPC4StatsnWorkers=3
#    export HPC4StatsnTask1=120
#    export HPC4StatsnTask2=170
     
# run the batch job    
    R CMD batch ../src/supervisorBatch.R  laptopGPD.Rout
    
####################################################
# Running on cheyenne
####################################################

#In the UNIX shell and in the batch subdirectory

qsub cheyenneGPDProduction.pbs

#
# Take a look at this batch script to see how the batch job is set up
# The -quiet option in mpirun could be removed for better debugging
#
# This is setup to use 100+ cores across 3 nodes and ran in under a minute.
#

    
#################################################
#checking  results
# with an example how to reassemble from separate chunks
#################################################
# in R and setting working directory to this batch directory.

   fname<-  dir("../output")
   print( fname)
   
 # Make sure the fname list is just the single file or  chunks of output
 # that you want -- if not just edit this to be the right subset.
 # If you ran the job iwht output directory empty fname should have the
 # right filename(s).The default is to produce one output file/object.
 # No chunking is done. 
 
   look<- matrix( NA, nrow=288, ncol= 192)
   
 # assume everything in fname is a chunk from this run
 for (  iChunk in 1: length( fname)){
    load( paste0("../output/", fname[iChunk]) )
  # OK next step is mysterious the output are several separate data
  # objects that are lists. The result component has all the good stuff.
  # Note that the grid cells are part of the output so there is no confusion
  # what has been worked on 
    result<- (get(fname[iChunk]))$result
    N<- length(result)
    for(  k in 1 : N ){
    temp<- result[[k]]
    # fifth value is return level from fit
    look[temp$I,temp$J] <-  temp$outSummary[,5]
    }
 }   


library( fields)
#library( ncdf4)
# To avoid reading the large darta file the lon and lat grid has been
# saved previously:
# dataFileName <- paste0("/Users/nychka/Dropbox/Data/",
#  "pr_day_CCSM4_historical_r1i1p1_19550101-19891231.nc")
# dataHandle <- nc_open(dataFileName)
# lon<- ncvar_get(dataHandle, "lon")
# lat<- ncvar_get(dataHandle,"lat")
# save( lon, lat, file="../data/lonlatCCSM4.rda")
#

load( "../data/lonlatCCSM4.rda")
pdf("laptopGDPProductionPlot.pdf", width=8, height=5)
image.plot( lon,lat, log10(look))
map("world2", add=TRUE)
dev.off()






   